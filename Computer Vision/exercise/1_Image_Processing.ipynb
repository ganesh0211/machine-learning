{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ECMM426/ECMM441 - Image Processing.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-I1B_Co_p8O"
   },
   "source": [
    "<H1 style=\"text-align: center\">Computer Vision / Machine Vision</H1>\n",
    "<H1 style=\"text-align: center\"></H1>\n",
    "<H2 style=\"text-align: center\">Exercise 1</H2>\n",
    "<H2 style=\"text-align: center\">Image Processing</H2>\n",
    "\n",
    "Simple examples of image processing concepts on OpenCV.\n",
    "\n",
    "#### Note: Use Colab ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz0mc1j6XtZ-"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "du7rDC_N_p8O"
   },
   "source": [
    "import urllib\n",
    "import matplotlib, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "print('OpenCV version: {}'.format(cv2.__version__))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KMakUW3Xx66"
   },
   "source": [
    "## Download Images\n",
    "Download some images and prepare for reading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9Puj7AIVHLEa"
   },
   "source": [
    "import os\n",
    "if not os.path.exists('images.zip'):\n",
    "  !wget --no-check-certificate https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/images.zip\n",
    "  !unzip -q images.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa-P3IIU_p8R"
   },
   "source": [
    "## Image Data Structures in OpenCV\n",
    "Color images have three channels: red, green and blue"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k3s5jaMW_p8S"
   },
   "source": [
    "# read an image\n",
    "img = cv2.imread('images/lena.png')\n",
    "\n",
    "# show image format (basically a 3-d array of pixel color info, in BGR format)\n",
    "print('Image shape: {}'.format(img.shape))\n",
    "print('Image: {}'.format(img))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZPEVuGh_p8V"
   },
   "source": [
    "## Color Conversions\n",
    "By default OpenCV loads images in BGR format."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uPBA122WEzXM"
   },
   "source": [
    "# show image with matplotlib\n",
    "plt.imshow(img)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_kIGhwKc_p8V",
    "scrolled": true
   },
   "source": [
    "# convert image to RGB color space\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# show image with matplotlib\n",
    "plt.imshow(img)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vpS6RcOV_p8Y"
   },
   "source": [
    "# convert image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "print('Image shape: {}'.format(gray_img.shape))\n",
    "# grayscale image represented as a 2-d array\n",
    "print(gray_img)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1yoDp2hCihi"
   },
   "source": [
    "Gray images have single channel"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z2-K1pOh_p8a"
   },
   "source": [
    "# plot the gray image, note the cmap parameter\n",
    "plt.imshow(gray_img, cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL3RlGbQ_p8c"
   },
   "source": [
    "## Average color of an image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1QZGyF84_p8d"
   },
   "source": [
    "# find average per row\n",
    "# np.average() takes in an axis argument which finds the average across that axis. \n",
    "average_color_per_row = np.average(img, axis=0)\n",
    "\n",
    "# find average across average per row\n",
    "average_color = np.average(average_color_per_row, axis=0)\n",
    "\n",
    "# convert back to uint8\n",
    "average_color = np.uint8(average_color)\n",
    "print(average_color)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GXmzBFMf_p8f"
   },
   "source": [
    "# create 100 x 100 pixel array with average color value\n",
    "average_color_img = np.array([[average_color]*100]*100, np.uint8)\n",
    "\n",
    "plt.imshow(average_color_img)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAvdTtHeKQJJ"
   },
   "source": [
    "## Box Filtering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HVb5aZSNLaGK"
   },
   "source": [
    "img = cv2.cvtColor(cv2.imread('images/books.jpg'), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gS2OY6czd2oX"
   },
   "source": [
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "blur_img = cv2.blur(gray_img, (10, 10))\n",
    "plt.subplot(1, 2, 1); plt.imshow(gray_img, cmap='gray')\n",
    "plt.subplot(1, 2, 2); plt.imshow(blur_img, cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orKswuhZ0G5O"
   },
   "source": [
    "### Ringing Artifact"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nJOedoEeOu1d"
   },
   "source": [
    "# box filtering with 20x20 kernel\n",
    "blur = cv2.blur(img, (20, 20))\n",
    "plt.imshow(blur)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CU5ON7i1lQrs"
   },
   "source": [
    "gray_img = cv2.imread('images/grass.png')\n",
    "blur_img = cv2.blur(gray_img, (25, 25))\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1); plt.imshow(gray_img, cmap='gray')\n",
    "plt.subplot(1, 2, 2); plt.imshow(blur_img, cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhoKd7Is_p8y"
   },
   "source": [
    "## Gaussian Filtering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R2qNZNzB_p8z"
   },
   "source": [
    "img = cv2.cvtColor(cv2.imread('images/oy.jpg'), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FcEcRBhT_p81"
   },
   "source": [
    "# preproccess with blurring, with 5x5 kernel (note kernel size should be odd)\n",
    "img_blur_small = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "plt.imshow(img_blur_small)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GcpJwBNU_p83"
   },
   "source": [
    "img_blur_small = cv2.GaussianBlur(img, (5,5), 25)\n",
    "plt.imshow(img_blur_small)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GW_zbFBx_p85"
   },
   "source": [
    "img_blur_large = cv2.GaussianBlur(img, (15,15), 0)\n",
    "plt.imshow(img_blur_large)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91vaF1kFUeAH"
   },
   "source": [
    "## Unsharp Masking or Sharpening\n",
    "\\begin{align}\n",
    "I_\\text{sharp} &= I_\\text{original} + \\alpha I_\\text{detail}\\\\\n",
    "               &= I_\\text{original} + \\alpha I_\\text{original} - \\alpha I_\\text{blurred}\\\\\n",
    "               &=(1+\\alpha)I_\\text{original} - \\alpha I_\\text{blurred}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ek_AhO6yUzaL"
   },
   "source": [
    "alpha = 0.5\n",
    "img = cv2.cvtColor(cv2.imread('images/oy.jpg'), cv2.COLOR_BGR2RGB)\n",
    "img_sharp = cv2.addWeighted(img, 1.0 + alpha, img_blur_large, -alpha, 0)\n",
    "plt.subplot(1, 3, 1); plt.imshow(img); plt.title('Original');\n",
    "plt.subplot(1, 3, 2); plt.imshow(img_blur_large); plt.title('Gaussian Blurred');\n",
    "plt.subplot(1, 3, 3); plt.imshow(img_sharp); plt.title('Sharp');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFRJL4v1O7kt"
   },
   "source": [
    "## Median Filtering\n",
    "First create the function for creating noisy images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dqMvcYl3u_S8"
   },
   "source": [
    "def add_sp_noise(image, amount=0.1):\n",
    "    row, col, ch = image.shape\n",
    "    s_vs_p = 0.5\n",
    "    out = np.copy(image)\n",
    "    # Salt mode\n",
    "    num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "            for i in image.shape]\n",
    "    out[coords[0], coords[1], coords[2]] = 1\n",
    "\n",
    "    # Pepper mode\n",
    "    num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "            for i in image.shape]\n",
    "    out[coords[0], coords[1], coords[2]] = 0\n",
    "    return out"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBNSgJgfDgqv"
   },
   "source": [
    "Load an image and apply salt and pepper noise and then try to smooth it with Gaussian and Median filter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ea2GEwfFQLR1"
   },
   "source": [
    "img = cv2.cvtColor(cv2.imread('images/coins.jpg'), cv2.COLOR_BGR2RGB)\n",
    "noisy_img = add_sp_noise(img, amount=0.1)\n",
    "img_gaus = cv2.GaussianBlur(noisy_img, (5, 5), 3)\n",
    "img_med = cv2.medianBlur(noisy_img, 5)\n",
    "plt.subplot(1, 4, 1); plt.imshow(img); plt.title('Original');\n",
    "plt.subplot(1, 4, 2); plt.imshow(noisy_img); plt.title('Salt & Pepper Noise');\n",
    "plt.subplot(1, 4, 3); plt.imshow(img_gaus); plt.title('Gaussian Filtered');\n",
    "plt.subplot(1, 4, 4); plt.imshow(img_med); plt.title('Median Filtered');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsMTsTPgJFpn"
   },
   "source": [
    "## Image Gradient\n",
    "Experiment with negative values. Note `cv2.CV_8U` cannot contain negative values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S__gzVUHI3Sg"
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('images/books.jpg', 0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_8U)\n",
    "sobelx = cv2.Sobel(img, cv2.CV_8U, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(img, cv2.CV_8U, 0, 1, ksize=5)\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian, cmap = 'gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely, cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETdR_tnDQ2gr"
   },
   "source": [
    "Note `cv2.CV_64F` can contain negative values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Qv2iZjSKbUI"
   },
   "source": [
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(laplacian, cmap = 'gray')\n",
    "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx, cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely, cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxeFuSii_p9N"
   },
   "source": [
    "## Edge Detection\n",
    "Canny edge detector on OpenCV. Usage of edge detection versus thresholding to obtain binary image."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-utaqZp5SDP7"
   },
   "source": [
    "cups = cv2.cvtColor(cv2.imread('images/cups.jpg'), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(cups)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7Ko1a2jmSM-M"
   },
   "source": [
    "# preprocess by blurring and grayscale\n",
    "cups_preprocessed  = cv2.cvtColor(cv2.GaussianBlur(cups, (7,7), 0), cv2.COLOR_RGB2GRAY)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a8-A44piSmwd"
   },
   "source": [
    "# find binary image with thresholding\n",
    "low_thresh = 120\n",
    "high_thresh = 200\n",
    "_, cups_thresh = cv2.threshold(cups_preprocessed, low_thresh, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(cv2.cvtColor(cups_thresh, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "_, cups_thresh_hi = cv2.threshold(cups_preprocessed, high_thresh, 255, cv2.THRESH_BINARY)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lVNkDIgDRuci"
   },
   "source": [
    "# find binary image with edges\n",
    "cups_edges = cv2.Canny(cups_preprocessed, threshold1=90, threshold2=110)\n",
    "plt.imshow(cv2.cvtColor(cups_edges, cv2.COLOR_GRAY2RGB))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNSH07PW_p8i"
   },
   "source": [
    "## Binary Thresholding\n",
    "\n",
    "Binarization converts an image to a two tone (0,255 or 0,1) image. Examples using thresholding on brightness/darkness of grayscale image and on color ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NcGsSOG_p8i"
   },
   "source": [
    "### On Grayscale Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqxBVLMZx7q8"
   },
   "source": [
    "### Global Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RX8Ro0wy_p8j"
   },
   "source": [
    "# threshold for grayscale image\n",
    "img = cv2.imread('images/oy.jpg')\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, threshold_img = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1); plt.imshow(gray_img, cmap='gray')\n",
    "plt.subplot(1, 2, 2); plt.imshow(threshold_img, cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vPiYT2jV_p88"
   },
   "source": [
    "#threshold on blurred image\n",
    "gray_blur_img = cv2.cvtColor(img_blur_small, cv2.COLOR_BGR2GRAY)\n",
    "_, threshold_img_blur = cv2.threshold(gray_blur_img, 100, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(cv2.cvtColor(threshold_img_blur, cv2.COLOR_GRAY2RGB))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vvQVIfwymzn"
   },
   "source": [
    "### Adaptive Thresholding\n",
    "It is local thresholding where threshold is decided in local windows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PZriyxc5_p8-"
   },
   "source": [
    "# using adaptive threshold instead of global\n",
    "adaptive_thresh = cv2.adaptiveThreshold(gray_img,255,\\\n",
    "                                         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                                         cv2.THRESH_BINARY,11,2)\n",
    "plt.imshow(adaptive_thresh, cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgkeDdwO_p8l"
   },
   "source": [
    "### On Color Image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_MT2nEBD_p8l"
   },
   "source": [
    "# open new Mondrian Piet painting photo\n",
    "piet = cv2.cvtColor(cv2.imread('images/piet.png'), cv2.COLOR_BGR2RGB)\n",
    "piet_hsv = cv2.cvtColor(piet, cv2.COLOR_RGB2HSV)\n",
    "plt.imshow(piet)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B2u0XXaIZr-"
   },
   "source": [
    "### Range thresholding\n",
    "The HSV color space is quite similar to the way in which humans perceive color. Most of the other models define color in relation to the primary colors. The colors used in HSV can be clearly defined by human perception."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lXYfyn34_p8q"
   },
   "source": [
    "# threshold for hue channel in blue range\n",
    "blue_min = np.array([85, 60, 60], np.uint8)\n",
    "blue_max = np.array([150, 255, 255], np.uint8)\n",
    "threshold_blue_img = cv2.inRange(piet_hsv, blue_min, blue_max)\n",
    "\n",
    "# show threshold bits\n",
    "plt.imshow(threshold_blue_img, cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hk-tEWDJ_p8s"
   },
   "source": [
    "### Binary Thesholding and Image Masking"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "phG9prlm_p8s"
   },
   "source": [
    "upstate = cv2.cvtColor(cv2.imread('images/upstate-ny.jpg'), cv2.COLOR_BGR2RGB)\n",
    "upstate_hsv = cv2.cvtColor(upstate, cv2.COLOR_RGB2HSV)\n",
    "plt.imshow(upstate)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThygluzRHth8"
   },
   "source": [
    "Note `bitwise_not` to filter out the blue sky"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bXNZJRpe_p8v"
   },
   "source": [
    "mask_inverse = cv2.inRange(upstate_hsv, blue_min, blue_max)\n",
    "mask = cv2.bitwise_not(mask_inverse)\n",
    "plt.imshow(mask, cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWiloWutH8Ly"
   },
   "source": [
    "Use the above mask to select the non sky part"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yLAtT3TY_p8w"
   },
   "source": [
    "# convert single channel mask back into 3 channels\n",
    "mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# perform bitwise and on mask to obtain cut-out image that is not blue\n",
    "masked_upstate = cv2.bitwise_and(upstate, mask_rgb)\n",
    "\n",
    "# replace the cut-out parts with white\n",
    "masked_replace_white = cv2.addWeighted(masked_upstate, 1, \\\n",
    "                                       cv2.cvtColor(mask_inverse, cv2.COLOR_GRAY2RGB), 1, 0)\n",
    "\n",
    "plt.imshow(masked_replace_white)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}